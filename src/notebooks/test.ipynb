{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'votes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f5f65c4854b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 第三维度提到最前\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mvotes_trans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvotes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvotes_t_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'votes' is not defined"
     ]
    }
   ],
   "source": [
    "num_dims = 6\n",
    "\n",
    "votes_t_shape = [3, 0, 1, 2]\n",
    "for i in range(num_dims - 4):\n",
    "    votes_t_shape += [i + 4]  # CONV: votes_t_shape - [3, 0, 1, 2, 4, 5]\n",
    "    \n",
    "r_t_shape = [1, 2, 3, 0]\n",
    "for i in range(num_dims - 4):\n",
    "    r_t_shape += [i + 4]  # CONV: votes_t_shape - [1, 2, 3, 0, 4, 5]\n",
    "\n",
    "# 第三维度提到最前\n",
    "votes_trans = tf.transpose(votes, votes_t_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0\n",
      "epoch: 2, loss: 0\n",
      "epoch: 4, loss: 0\n",
      "epoch: 6, loss: 0\n",
      "epoch: 8, loss: 0\n",
      "epoch: 10, loss: 0\n",
      "epoch: 12, loss: 0\n",
      "epoch: 14, loss: 0\n",
      "epoch: 16, loss: 0\n",
      "epoch: 18, loss: 0\n",
      "epoch: 20, loss: 0\n",
      "epoch: 22, loss: 0\n",
      "epoch: 24, loss: 0\n",
      "epoch: 26, loss: 0\n",
      "epoch: 28, loss: 0\n",
      "train finished...\n",
      "final loss: 0.396\n",
      "weight_1:\n",
      " [[ 0.33544922  0.40966797  0.05038452]\n",
      " [-0.17602539  0.61669922 -0.59326172]\n",
      " [ 0.44262695 -0.27441406  0.77880859]]\n",
      "bias_1:\n",
      " [-0.00751114 -0.04244995  0.05822754]\n",
      "weight_2:\n",
      " [[-0.33251953  0.45068359]\n",
      " [-0.27392578  0.08459473]\n",
      " [ 0.43652344 -0.08465576]]\n",
      "bias_2:\n",
      " [ 0.16186523  0.11657715]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# data\n",
    "x_train = np.random.random([100, 3])\n",
    "y_train = np.rint(np.random.random([100, 2]))\n",
    " \n",
    "epochs = 30\n",
    "display_step = 2\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    # input, output\n",
    "    x = tf.placeholder(dtype=tf.float16, shape=[100, 3], name=\"input\")\n",
    "    y = tf.placeholder(dtype=tf.float16, shape=[100, 2], name=\"label\")\n",
    "    \n",
    "    with tf.variable_scope('fc_1'):\n",
    "      w_1 = tf.get_variable(\n",
    "          'weights',\n",
    "          shape=[3, 3], \n",
    "          initializer=tf.contrib.layers.xavier_initializer(), \n",
    "          dtype=tf.float16)\n",
    "      b_1 = tf.get_variable(\n",
    "          'bias',\n",
    "          shape=[3], \n",
    "          initializer=tf.zeros_initializer(), \n",
    "          dtype=tf.float16)\n",
    "      z_1 = tf.matmul(x, w_1) + b_1\n",
    "    \n",
    "    with tf.variable_scope('fc_2'):\n",
    "      w_2 = tf.get_variable(\n",
    "          'weights',\n",
    "          shape=[3, 2], \n",
    "          initializer=tf.contrib.layers.xavier_initializer(), \n",
    "          dtype=tf.float16)\n",
    "      b_2 = tf.get_variable(\n",
    "          'bias',\n",
    "          shape=[2], \n",
    "          initializer=tf.zeros_initializer(), \n",
    "          dtype=tf.float16)\n",
    "      z_2 = tf.matmul(z_1, w_2) + b_2\n",
    "    \n",
    "    # loss functon\n",
    "    cost = tf.reduce_mean(tf.square(y - z_2))\n",
    "    \n",
    "    optim = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "    saver = tf.train.Saver(max_to_keep=4)\n",
    "  \n",
    "\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(epochs):\n",
    "        sess.run(optim, feed_dict={x:x_train, y:y_train})\n",
    "        if epoch % display_step == 0:\n",
    "            loss = sess.run(cost, feed_dict={x:x_train, y:y_train})\n",
    "            print(\"epoch: %d, loss: %d\" %(epoch, loss))\n",
    "            # 保存训练过程中的模型\n",
    "            saver.save(sess, \"line_regression_model/regress.cpkt\", global_step=epoch)\n",
    "    print(\"train finished...\")\n",
    "    # 保存最终的模型\n",
    "    saver.save(sess, \"line_regression_model/regress.cpkt\")\n",
    "    print(\"final loss:\", sess.run(cost, feed_dict={x:x_train, y:y_train}))\n",
    "    print(\"weight_1:\\n\", sess.run(w_1))\n",
    "    print(\"bias_1:\\n\", sess.run(b_1))\n",
    "    print(\"weight_2:\\n\", sess.run(w_2))\n",
    "    print(\"bias_2:\\n\", sess.run(b_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from line_regression_model/regress.cpkt\n",
      "weight_1:\n",
      " [[ 0.33544922  0.40966797  0.05038452]\n",
      " [-0.17602539  0.61669922 -0.59326172]\n",
      " [ 0.44262695 -0.27441406  0.77880859]]\n",
      "bias_1:\n",
      " [-0.00751114 -0.04244995  0.05822754]\n",
      "weight_2:\n",
      " [[-0.33251953  0.45068359]\n",
      " [-0.27392578  0.08459473]\n",
      " [ 0.43652344 -0.08465576]]\n",
      "bias_2:\n",
      " [ 0.16186523  0.11657715]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    checkpoint_path = tf.train.latest_checkpoint('line_regression_model/')\n",
    "    loader = tf.train.import_meta_graph(checkpoint_path + '.meta')\n",
    "    loader.restore(sess, checkpoint_path)\n",
    "    w_1_new = sess.run(loaded_graph.get_tensor_by_name(\"fc_1/weights:0\"))\n",
    "    b_1_new = sess.run(loaded_graph.get_tensor_by_name(\"fc_1/bias:0\"))\n",
    "    w_2_new = sess.run(loaded_graph.get_tensor_by_name(\"fc_2/weights:0\"))\n",
    "    b_2_new = sess.run(loaded_graph.get_tensor_by_name(\"fc_2/bias:0\"))\n",
    "    \n",
    "print(\"weight_1:\\n\", w_1_new)\n",
    "print(\"bias_1:\\n\", b_1_new)\n",
    "print(\"weight_2:\\n\", w_2_new)\n",
    "print(\"bias_2:\\n\", b_2_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_1:\n",
      " [[ 0.33544922  0.40966797  0.05038452]\n",
      " [-0.17602539  0.61669922 -0.59326172]\n",
      " [ 0.44262695 -0.27441406  0.77880859]]\n",
      "bias_1:\n",
      " [-0.00751114 -0.04244995  0.05822754]\n",
      "weight_2:\n",
      " [[-0.33251953  0.45068359]\n",
      " [-0.27392578  0.08459473]\n",
      " [ 0.43652344 -0.08465576]]\n",
      "bias_2:\n",
      " [ 0.16186523  0.11657715]\n",
      "epoch: 0, loss: 0\n",
      "epoch: 2, loss: 0\n",
      "epoch: 4, loss: 0\n",
      "epoch: 6, loss: 0\n",
      "epoch: 8, loss: 0\n",
      "epoch: 10, loss: 0\n",
      "epoch: 12, loss: 0\n",
      "epoch: 14, loss: 0\n",
      "epoch: 16, loss: 0\n",
      "epoch: 18, loss: 0\n",
      "epoch: 20, loss: 0\n",
      "epoch: 22, loss: 0\n",
      "epoch: 24, loss: 0\n",
      "epoch: 26, loss: 0\n",
      "epoch: 28, loss: 0\n",
      "train finished...\n",
      "final loss: 0.27856\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# data\n",
    "x_train = np.random.random([100, 3])\n",
    "y_train = np.rint(np.random.random([100, 2]))\n",
    " \n",
    "epochs = 30\n",
    "display_step = 2\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    # input, output\n",
    "    x = tf.placeholder(dtype=tf.float16, shape=[100, 3], name=\"input\")\n",
    "    y = tf.placeholder(dtype=tf.float16, shape=[100, 2], name=\"label\")\n",
    "    \n",
    "    with tf.variable_scope('fc_1'):\n",
    "      w_1 = tf.Variable(initial_value=w_1_new, trainable=True)\n",
    "      b_1 = tf.Variable(initial_value=b_1_new, trainable=True)\n",
    "      z_1 = tf.matmul(x, w_1) + b_1\n",
    "    \n",
    "    with tf.variable_scope('fc_2'):\n",
    "      w_2 = tf.Variable(initial_value=w_2_new, trainable=True)\n",
    "      b_2 = tf.Variable(initial_value=b_2_new, trainable=True)\n",
    "      z_2 = tf.matmul(z_1, w_2) + b_2\n",
    "      \n",
    "    with tf.variable_scope('fc_3'):\n",
    "      w_3 = tf.get_variable(\n",
    "          'weights',\n",
    "          shape=[2, 2], \n",
    "          initializer=tf.contrib.layers.xavier_initializer(), \n",
    "          dtype=tf.float16)\n",
    "      b_3 = tf.get_variable(\n",
    "          'bias',\n",
    "          shape=[2], \n",
    "          initializer=tf.zeros_initializer(), \n",
    "          dtype=tf.float16)\n",
    "      z_3 = tf.matmul(z_2, w_3) + b_3\n",
    "    \n",
    "    # loss functon\n",
    "    cost = tf.reduce_mean(tf.square(y - z_3))\n",
    "    \n",
    "    optim = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "    saver = tf.train.Saver(max_to_keep=4)\n",
    "  \n",
    "\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"weight_1:\\n\", sess.run(w_1))\n",
    "    print(\"bias_1:\\n\", sess.run(b_1))\n",
    "    print(\"weight_2:\\n\", sess.run(w_2))\n",
    "    print(\"bias_2:\\n\", sess.run(b_2))\n",
    "    for epoch in range(epochs):\n",
    "        sess.run(optim, feed_dict={x:x_train, y:y_train})\n",
    "        if epoch % display_step == 0:\n",
    "            loss = sess.run(cost, feed_dict={x:x_train, y:y_train})\n",
    "            print(\"epoch: %d, loss: %d\" %(epoch, loss))\n",
    "            # 保存训练过程中的模型\n",
    "            saver.save(sess, \"line_regression_model/regress.cpkt\", global_step=epoch)\n",
    "    print(\"train finished...\")\n",
    "    # 保存最终的模型\n",
    "    saver.save(sess, \"line_regression_model/regress.cpkt\")\n",
    "    print(\"final loss:\", sess.run(cost, feed_dict={x:x_train, y:y_train}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
